import os
import urllib.parse
import base64
import logging
import re
from collections import defaultdict
from uuid import uuid4

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('node_cleaning_errors.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def clean_duplicate_nodes_advanced(file_path, output_path=None, debug_samples=10, strict_dedup=True):
    """
    æ¸…ç†èŠ‚ç‚¹æ–‡ä»¶ä¸­é‡å¤çš„èŠ‚ç‚¹ï¼ŒåŸºäºåè®®ç‰¹å®šé€»è¾‘ï¼Œæ”¯æŒ VLESSã€Trojanã€SS ç­‰åè®®ã€‚
    
    Args:
        file_path (str): è¾“å…¥èŠ‚ç‚¹æ–‡ä»¶è·¯å¾„ã€‚
        output_path (str, optional): è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤åœ¨è¾“å…¥æ–‡ä»¶åååŠ  '_cleaned'ã€‚
        debug_samples (int): è°ƒè¯•æ—¶è®°å½•çš„å»é‡é”®æ ·æœ¬æ•°ã€‚
        strict_dedup (bool): æ˜¯å¦å¯ç”¨ä¸¥æ ¼å»é‡ï¼ˆå¿½ç•¥ UUID/å¯†ç ï¼Œä»…æ¯”è¾ƒ host:port å’Œå…³é”®å‚æ•°ï¼‰ã€‚
    
    Returns:
        bool: æ¸…ç†æˆåŠŸè¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
    """
    if not os.path.isfile(file_path):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False

    if output_path is None:
        base, ext = os.path.splitext(file_path)
        output_path = f"{base}_cleaned{ext}"

    unique_node_keys = set()
    unique_lines_output = []
    error_lines = []
    stats = defaultdict(int)
    debug_keys = []

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_number, line in enumerate(f, 1):
                stats['total_lines'] += 1
                stripped_line = line.strip()
                if not stripped_line:
                    stats['empty_lines'] += 1
                    continue

                core_part = stripped_line.split('#')[0].strip()
                protocol = core_part.split('://')[0].lower()
                stats[protocol] += 1

                try:
                    node_key = generate_node_key(core_part, strict_dedup)
                    if not node_key:
                        raise ValueError("æ— æ³•ç”Ÿæˆå»é‡é”®")

                    if len(debug_keys) < debug_samples:
                        debug_keys.append((protocol, node_key))

                    if node_key not in unique_node_keys:
                        unique_node_keys.add(node_key)
                        unique_lines_output.append(line)
                    else:
                        stats[f"{protocol}_duplicates"] += 1
                except Exception as e:
                    logger.error(f"è§£æå¤±è´¥ (è¡Œ {line_number}): {stripped_line} | é”™è¯¯: {str(e)}")
                    error_lines.append((line_number, stripped_line, str(e)))
                    stats[f"{protocol}_errors"] += 1

        with open(output_path, 'w', encoding='utf-8') as f:
            f.writelines(unique_lines_output)

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"âœ… æ¸…ç†å®Œæˆï¼Œç»“æœä¿å­˜è‡³: {output_path}")
        logger.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  - æ€»è¡Œæ•°: {stats['total_lines']}")
        logger.info(f"  - æœ‰æ•ˆè¡Œæ•°: {stats['total_lines'] - stats['empty_lines']}")
        logger.info(f"  - å”¯ä¸€èŠ‚ç‚¹æ•°: {len(unique_lines_output)}")
        total_duplicates = sum(stats[f'{p}_duplicates'] for p in ['vless', 'trojan', 'ss', 'vmess', 'ssr', 'hysteria2'])
        logger.info(f"  - é‡å¤èŠ‚ç‚¹æ•°: {total_duplicates}")
        logger.info(f"  - è§£æå¤±è´¥æ•°: {len(error_lines)}")
        logger.info(f"  - ç©ºè¡Œæ•°: {stats['empty_lines']}")
        logger.info(f"  - åè®®åˆ†å¸ƒ:")
        for protocol in ['vless', 'trojan', 'ss', 'vmess', 'ssr', 'hysteria2', 'unknown']:
            if stats[protocol] or stats.get(f'{protocol}_duplicates', 0) or stats.get(f'{protocol}_errors', 0):
                logger.info(f"    - {protocol.upper()}: {stats[protocol]} èŠ‚ç‚¹, "
                           f"{stats.get(f'{protocol}_duplicates', 0)} é‡å¤, "
                           f"{stats.get(f'{protocol}_errors', 0)} è§£æå¤±è´¥")

        if error_lines:
            logger.warning(f"è§£æå¤±è´¥èŠ‚ç‚¹: {len(error_lines)}ï¼Œè¯¦æƒ…è§ node_cleaning_errors.log")

        if debug_keys:
            logger.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯: å‰ {len(debug_keys)} ä¸ªå»é‡é”®:")
            for i, (proto, key) in enumerate(debug_keys, 1):
                logger.info(f"    {i}. {proto.upper()}: {key}")

        return True

    except Exception as e:
        logger.error(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

def generate_node_key(url, strict_dedup):
    """ç”ŸæˆèŠ‚ç‚¹çš„å»é‡é”®ï¼ŒåŸºäºåè®®ç±»å‹æ ‡å‡†åŒ–å¤„ç†ã€‚"""
    try:
        parsed = urllib.parse.urlparse(url)
        scheme = parsed.scheme.lower()
        netloc = parsed.netloc.lower()
        query = parsed.query

        handlers = {
            'vless': normalize_vless,
            'vmess': normalize_vmess,
            'trojan': normalize_trojan,
            'ss': normalize_ss,
            'ssr': normalize_ssr,
            'hysteria2': normalize_hysteria2
        }

        handler = handlers.get(scheme)
        if handler:
            return handler(netloc, query, strict_dedup)
        
        logger.warning(f"æœªçŸ¥åè®®: {scheme}ï¼Œä½¿ç”¨åŸå§‹ URL ä½œä¸ºå»é‡é”®")
        return url.lower()

    except Exception as e:
        raise ValueError(f"ç”Ÿæˆå»é‡é”®å¤±è´¥: {str(e)}")

def normalize_vless(netloc, query, strict_dedup):
    """æ ‡å‡†åŒ– VLESS é“¾æ¥ã€‚"""
    host_port = netloc.split('@')[1] if strict_dedup and '@' in netloc else netloc
    query_params = urllib.parse.parse_qs(query)
    key_params = {k: sorted([urllib.parse.quote(urllib.parse.unquote(p)) if k == 'path' else p 
                            for p in query_params[k]]) 
                  for k in ['type', 'path', 'security', 'encryption'] if k in query_params}
    sorted_query = urllib.parse.urlencode(key_params, doseq=True)
    return f"vless://{host_port}?{sorted_query}"

def normalize_vmess(netloc, strict_dedup):
    """æ ‡å‡†åŒ– VMESS é“¾æ¥ã€‚"""
    try:
        netloc = netloc + '=' * (4 - len(netloc) % 4) if len(netloc) % 4 else netloc
        decoded = base64.urlsafe_b64decode(netloc).decode('utf-8')
        match = re.search(r'"add":"([^"]+)".*"port":(\d+)', decoded)
        if match:
            host, port = match.groups()
            return f"vmess://{host}:{port}"
        logger.warning(f"VMESS JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ netloc: {netloc}")
        return f"vmess://{netloc}"
    except Exception as e:
        logger.warning(f"VMESS è§£æå¤±è´¥: {netloc} | é”™è¯¯: {str(e)}")
        return f"vmess://{netloc}"

def normalize_trojan(netloc, query, strict_dedup):
    """æ ‡å‡†åŒ– Trojan é“¾æ¥ã€‚"""
    host_port = netloc.split('@')[1] if strict_dedup and '@' in netloc else netloc
    query_params = urllib.parse.parse_qs(query)
    key_params = {k: sorted(query_params[k]) for k in ['type', 'sni'] if k in query_params}
    sorted_query = urllib.parse.urlencode(key_params, doseq=True)
    return f"trojan://{host_port}?{sorted_query}"

def normalize_ss(netloc, query, strict_dedup):
    """æ ‡å‡†åŒ– SS é“¾æ¥ã€‚"""
    try:
        method_password_b64, host_port =çš„å¥³0

        method_password_b64 = re.sub(r'[^A-Za-z0-9+/=]', '', netloc)
        method_password_b64 += '=' * (4 - len(method_password_b64) % 4) if len(method_password_b64) % 4 else method_password_b64

        try:
            config = base64.urlsafe_b64decode(method_password_b64).decode('utf-8')
            method, password = config.split(':', 1) if ':' in config else (config, '')
        except Exception as e:
            logger.warning(f"SS Base64 è§£ç å¤±è´¥: {method_password_b64} | é”™è¯¯: {str(e)}")
            return f"ss://{host_port}" if strict_dedup else f"ss://{method_password_b64}@{host_port}"

        return f"ss://{host_port}" if strict_dedup else f"ss://{method}:{password}@{host_port}"
    except Exception as e:
        raise ValueError(f"SS è§£æå¤±è´¥: {str(e)}")

def normalize_ssr(netloc, strict_dedup):
    """æ ‡å‡†åŒ– SSR é“¾æ¥ã€‚"""
    try:
        netloc = netloc + '=' * (4 - len(netloc) % 4) if len(netloc) % 4 else netloc
        decoded = base64.urlsafe_b64decode(netloc).decode('utf-8')
        parts = decoded.split(':')
        if len(parts) >= 2:
            return f"ssr://{parts[0]}:{parts[1]}"
        return f"ssr://{netloc}"
    except Exception as e:
        logger.warning(f"SSR è§£ç å¤±è´¥: {netloc} | é”™è¯¯: {str(e)}")
        return f"ssr://{netloc}"

def normalize_hysteria2(netloc, query, strict_dedup):
    """æ ‡å‡†åŒ– Hysteria2 é“¾æ¥ã€‚"""
    query_params = urllib.parse.parse_qs(query)
    key_params = {k: sorted(query_params[k]) for k in ['type', 'obfs'] if k in query_params}
    sorted_query = urllib.parse.urlencode(key_params, doseq=True)
    return f"hysteria2://{netloc}?{sorted_query}"

if __name__ == "__main__":
    nodes_file = os.path.join('data', 'å–§1

    clean_duplicate_nodes_advanced(nodes_file, debug_samples=10, strict_dedup=True)
