import os
import urllib.parse
import base64
import logging
import re
from collections import defaultdict

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('node_cleaning_errors.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def clean_duplicate_nodes_advanced(file_path, output_path=None, debug_samples=10, strict_dedup=False):
    """
    è¯»å–æ–‡ä»¶ï¼ŒåŸºäºåè®®ç‰¹å®šè§£æé€»è¾‘ç§»é™¤é‡å¤è¡Œï¼Œä¿å­˜åˆ°æ–°æ–‡ä»¶ï¼Œå¹¶æä¾›è¯¦ç»†ç»Ÿè®¡æ•°æ®ã€‚
    æ”¯æŒ VLESSã€Trojanã€SS åè®®ï¼Œå¿½ç•¥éå…³é”®å­—æ®µï¼ˆå¦‚å¤‡æ³¨ã€fpï¼‰ï¼Œè®°å½•è§£æå¤±è´¥çš„èŠ‚ç‚¹ã€‚
    debug_samples: è®°å½•å‰ N ä¸ªå»é‡é”®ç”¨äºè°ƒè¯•ã€‚
    strict_dedup: å¦‚æœä¸º Trueï¼Œä»…æ¯”è¾ƒ host:port å’Œå…³é”®å‚æ•°ï¼Œå¿½ç•¥ uuid/passwordã€‚
    """
    if output_path is None:
        base, ext = os.path.splitext(file_path)
        output_path = f"{base}_cleaned{ext}"

    unique_node_keys = set()  # å­˜å‚¨å»é‡é”®
    unique_lines_output = []  # å­˜å‚¨åŸå§‹è¡Œ
    error_lines = []         # å­˜å‚¨è§£æå¤±è´¥çš„è¡Œ
    stats = defaultdict(int)  # æŒ‰åè®®ç»Ÿè®¡èŠ‚ç‚¹æ•°
    line_count = 0
    debug_keys = []          # è°ƒè¯•ç”¨çš„å»é‡é”®æ ·æœ¬

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:  # æµå¼è¯»å–
                line_count += 1
                stripped_line = line.strip()
                if not stripped_line:
                    stats['empty_lines'] += 1
                    continue

                # åˆ†ç¦»æ ¸å¿ƒéƒ¨åˆ†å’Œå¤‡æ³¨
                hash_index = stripped_line.find('#')
                core_part = stripped_line[:hash_index].strip() if hash_index != -1 else stripped_line
                remark = stripped_line[hash_index:] if hash_index != -1 else ''

                # æå–åè®®å¹¶è®¡æ•°
                protocol = core_part.split('://')[0].lower()
                stats[protocol] += 1

                # è§£æå¹¶ç”Ÿæˆå»é‡é”®
                try:
                    node_key = generate_node_key(core_part, strict_dedup)
                    if node_key:
                        # è®°å½•å‰ debug_samples ä¸ªå»é‡é”®ç”¨äºè°ƒè¯•
                        if len(debug_keys) < debug_samples:
                            debug_keys.append((protocol, node_key))
                        if node_key not in unique_node_keys:
                            unique_node_keys.add(node_key)
                            unique_lines_output.append(line)
                        else:
                            stats[f"{protocol}_duplicates"] += 1
                    else:
                        raise ValueError("æ— æ³•ç”Ÿæˆå»é‡é”®")
                except Exception as e:
                    logging.error(f"è§£æèŠ‚ç‚¹å¤±è´¥ (è¡Œ {line_count}): {stripped_line} | é”™è¯¯: {e}")
                    error_lines.append((line_count, stripped_line, str(e)))
                    stats[f"{protocol}_errors"] += 1
                    continue

        # å†™å…¥ç»“æœ
        with open(output_path, 'w', encoding='utf-8') as f:
            f.writelines(unique_lines_output)

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logging.info(f"âœ… æˆåŠŸæ¸…ç†é‡å¤èŠ‚ç‚¹ã€‚ç»“æœä¿å­˜åˆ°: {output_path}")
        logging.info(f"ğŸ“Š ç»Ÿè®¡æ•°æ®:")
        logging.info(f"  - åŸå§‹èŠ‚ç‚¹æ•°: {line_count}")
        logging.info(f"  - æœ‰æ•ˆèŠ‚ç‚¹æ•°: {line_count - stats['empty_lines']}")
        logging.info(f"  - å”¯ä¸€èŠ‚ç‚¹æ•°: {len(unique_lines_output)}")
        logging.info(f"  - é‡å¤èŠ‚ç‚¹æ•°: {sum(stats[f'{p}_duplicates'] for p in ['vless', 'trojan', 'ss'])}")
        logging.info(f"  - è§£æå¤±è´¥èŠ‚ç‚¹æ•°: {len(error_lines)}")
        logging.info(f"  - ç©ºè¡Œæ•°: {stats['empty_lines']}")
        logging.info(f"  - æŒ‰åè®®åˆ†ç±»:")
        for protocol in ['vless', 'trojan', 'ss']:
            logging.info(f"    - {protocol.upper()}: {stats[protocol]} èŠ‚ç‚¹, {stats[f'{protocol}_duplicates']} é‡å¤, {stats[f'{protocol}_errors']} è§£æå¤±è´¥")
        if error_lines:
            logging.warning(f"è§£æå¤±è´¥çš„èŠ‚ç‚¹æ•°: {len(error_lines)}ï¼Œè¯¦æƒ…è§ node_cleaning_errors.log")
        if debug_keys:
            logging.info(f"ğŸ” è°ƒè¯•: å‰ {len(debug_keys)} ä¸ªå»é‡é”®æ ·æœ¬:")
            for i, (proto, key) in enumerate(debug_keys, 1):
                logging.info(f"    {i}. {proto.upper()}: {key}")

        return True

    except FileNotFoundError:
        logging.error(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return False
    except Exception as e:
        logging.error(f"âŒ æ¸…ç†èŠ‚ç‚¹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

def generate_node_key(url, strict_dedup=False):
    """æ ¹æ®åè®®ç”Ÿæˆå»é‡é”®ï¼Œä»…åŒ…å«å…³é”®å­—æ®µ"""
    try:
        parsed = urllib.parse.urlparse(url)
        scheme = parsed.scheme.lower()
        netloc = parsed.netloc.lower()  # è½¬æ¢ä¸ºå°å†™ä»¥é¿å…å¤§å°å†™å·®å¼‚
        query = parsed.query

        if scheme == "vless":
            return normalize_vless(netloc, query, strict_dedup)
        elif scheme == "trojan":
            return normalize_trojan(netloc, query, strict_dedup)
        elif scheme == "ss":
            return normalize_ss(netloc, url)
        else:
            # æœªè¯†åˆ«åè®®ï¼Œç›´æ¥è¿”å›åŸå§‹ URL
            return url.lower()
    except Exception as e:
        raise ValueError(f"è§£æ URL å¤±è´¥: {e}")

def normalize_vless(netloc, query, strict_dedup):
    """æ ‡å‡†åŒ– VLESS é“¾æ¥ï¼Œå¿½ç•¥éå…³é”®å­—æ®µ"""
    # å¦‚æœ strict_dedup=Trueï¼Œä»…ä½¿ç”¨ host:port å’Œå…³é”®å‚æ•°ï¼Œå¿½ç•¥ UUID
    if strict_dedup:
        try:
            _, host_port = netloc.split('@', 1)
        except ValueError:
            host_port = netloc
    else:
        host_port = netloc
    query_params = urllib.parse.parse_qs(query)
    key_params = {k: sorted(query_params[k]) for k in ['type', 'path', 'security', 'encryption'] if k in query_params}
    # è§„èŒƒåŒ– path å‚æ•°
    if 'path' in key_params:
        key_params['path'] = [urllib.parse.quote(urllib.parse.unquote(p)) for p in key_params['path']]
    sorted_query = urllib.parse.urlencode(key_params, doseq=True)
    return f"vless://{host_port}?{sorted_query}"

def normalize_trojan(netloc, query, strict_dedup):
    """æ ‡å‡†åŒ– Trojan é“¾æ¥"""
    # å¦‚æœ strict_dedup=Trueï¼Œä»…ä½¿ç”¨ host:portï¼Œå¿½ç•¥ password
    if strict_dedup:
        try:
            _, host_port = netloc.split('@', 1)
        except ValueError:
            host_port = netloc
    else:
        host_port = netloc
    query_params = urllib.parse.parse_qs(query)
    key_params = {k: sorted(query_params[k]) for k in ['type', 'sni'] if k in query_params}
    sorted_query = urllib.parse.urlencode(key_params, doseq=True)
    return f"trojan://{host_port}?{sorted_query}"

def normalize_ss(netloc, url):
    """æ ‡å‡†åŒ– SS é“¾æ¥ï¼Œå¢å¼ºå®¹é”™æ€§"""
    try:
        if '@' in netloc:
            b64_config, host_port = netloc.split('@', 1)
            # æ¸…ç† Base64 å­—ç¬¦ä¸²
            b64_config = re.sub(r'[^A-Za-z0-9+/=]', '', b64_config)
            # éªŒè¯ Base64 åˆæ³•æ€§
            if not re.match(r'^[A-Za-z0-9+/=]+$', b64_config):
                raise ValueError(f"æ— æ•ˆçš„ Base64 å­—ç¬¦ä¸²: {b64_config}")
            try:
                config = base64.urlsafe_b64decode(b64_config + '===').decode('utf-8')
                # éªŒè¯ method:password æ ¼å¼
                if ':' not in config:
                    raise ValueError(f"æ— æ•ˆçš„ SS é…ç½®æ ¼å¼: {config}")
                return f"ss://{config}@{host_port}"
            except (base64.binascii.Error, UnicodeDecodeError) as e:
                logging.warning(f"SS Base64 è§£ç å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ Base64 ä½œä¸ºé”®: {b64_config} | é”™è¯¯: {e}")
                return f"ss://{b64_config}@{host_port}"
        else:
            # æ¸…ç†å¹¶éªŒè¯ Base64
            netloc = re.sub(r'[^A-Za-z0-9+/=]', '', netloc)
            config = base64.urlsafe_b64decode(netloc + '===').decode('utf-8', errors='ignore')
            return f"ss://{config}"
    except Exception as e:
        raise ValueError(f"æ— æ³•è§£æ SS é…ç½®: {e}")

if __name__ == "__main__":
    nodes_file = os.path.join('data', 'a.isidomain.web.id.txt')
    clean_duplicate_nodes_advanced(nodes_file, debug_samples=10)
