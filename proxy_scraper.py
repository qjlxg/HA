import httpx
import asyncio
import re
import os
import aiofiles
import aiofiles.threadpool.text
import json
import yaml
import base64
from collections import defaultdict
import datetime
import hashlib
from bs4 import BeautifulSoup
import logging
import typing
import uuid
# import httpcore # ä¸å†ç›´æ¥å¯¼å…¥ï¼Œå› ä¸ºå…¶SSLErrorå±æ€§å¯èƒ½ä¸å­˜åœ¨

# é…ç½®æ—¥å¿—ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
logging.basicConfig(
    level=logging.INFO, # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ä¸º DEBUG, INFO, WARNING, ERROR
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join('data', 'proxy_scraper.log')),
        logging.StreamHandler()
    ]
)

DATA_DIR = "data"
ALL_NODES_FILE = os.path.join(DATA_DIR, "all.txt")
NODE_COUNT_CSV = os.path.join(DATA_DIR, "node_counts.csv")
CACHE_DIR = os.path.join(DATA_DIR, "cache")
CACHE_EXPIRATION_HOURS = 48  # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆå°æ—¶ï¼‰
CLEANUP_THRESHOLD_HOURS = 72  # ç¼“å­˜æ¸…ç†é˜ˆå€¼ï¼ˆå°æ—¶ï¼‰

# ç¡®ä¿æ•°æ®ç›®å½•å’Œç¼“å­˜ç›®å½•å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CACHE_DIR, exist_ok=True)

# å®šä¹‰æ”¯æŒçš„èŠ‚ç‚¹åè®®æ­£åˆ™
NODE_PATTERNS = {
    "hysteria2": re.compile(r"hysteria2:\/\/(?:[^:@\/]+(?::[^@\/]*)?@)?(?:\[[0-9a-fA-F:\.]+\]|[^:\/?#]+):\d+\/?(?:\?[^#]*)?(?:#.*)?"),
    "vmess": re.compile(r"vmess:\/\/[a-zA-Z0-9\-_+=/]+"),
    "trojan": re.compile(r"trojan:\/\/[^@]+@(?:\[[0-9a-fA-F:\.]+\]|[^:\/?#]+):\d+\/?(?:\?[^#]*)?(?:#.*)?"),
    "ss": re.compile(r"ss:\/\/(?:[a-zA-Z0-9\-_]+:[^@\/]+@(?:\[[0-9a-fA-F:\.]+\]|[^:\/?#]+):\d+|[a-zA-Z0-9\-_+=/]+)(?:#.*)?"),
    "ssr": re.compile(r"ssr:\/\/[a-zA-Z0-9\-_+=/]+"),
    "vless": re.compile(r"vless:\/\/[0-9a-fA-F\-]+@(?:\[[0-9a-fA-F:\.]+\]|[^:\/?#]+):\d+\/?(?:\?[^#]*)?(?:#.*)?"),
}

# å¹¶å‘é™åˆ¶
CONCURRENCY_LIMIT = 10

# æ”¯æŒçš„ Shadowsocks åŠ å¯†æ–¹æ³•
SS_METHODS = {
    "aes-256-gcm", "aes-128-gcm", "chacha20-ietf-poly1305", "chacha20-ietf",
    "aes-256-cfb", "aes-128-cfb", "rc4-md5", "none"
}

# æ”¯æŒçš„ ShadowsocksR åè®®å’Œæ··æ·†
SSR_PROTOCOLS = {"origin", "auth_sha1_v4", "auth_aes128_md5", "auth_aes128_sha1"}
SSR_OBFS = {"plain", "http_simple", "http_post", "tls1.2_ticket_auth"}

def is_valid_uuid(value: str) -> bool:
    """éªŒè¯å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ UUIDã€‚"""
    try:
        uuid.UUID(value)
        return True
    except ValueError:
        [cite_start]return False [cite: 149]

def is_valid_port(port: str) -> bool:
    """éªŒè¯ç«¯å£å·æ˜¯å¦æœ‰æ•ˆï¼ˆ1-65535ï¼‰ã€‚"""
    try:
        port_num = int(port)
        return 1 <= port_num <= 65535
    except ValueError:
        [cite_start]return False [cite: 149]

def is_valid_host(host: str) -> bool:
    """éªŒè¯ä¸»æœºæ˜¯å¦ä¸ºæœ‰æ•ˆçš„åŸŸåæˆ– IP åœ°å€ï¼ˆåŒ…æ‹¬ IPv6ï¼‰ã€‚"""
    if not host:
        [cite_start]return False [cite: 149]
    # ç¨å¾®æ”¾å®½å¯¹ä¸»æœºåçš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œä½¿å…¶æ›´é€šç”¨
    # å…è®¸åŒ…å«éæ ‡å‡†DNSå­—ç¬¦ï¼ˆä¾‹å¦‚ä¸‹åˆ’çº¿ï¼‰ï¼Œè¿™åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æ˜¯å…è®¸çš„
    [cite_start]return bool(re.match(r'^(?:\[[0-9a-fA-F:\.]+\]|[a-zA-Z0-9\.\-_]+)$', host)) [cite: 149]

def validate_node(node: str, protocol: str) -> tuple[bool, str]:
    """
    éªŒè¯èŠ‚ç‚¹æ˜¯å¦ç¬¦åˆå…¶åè®®çš„å®˜æ–¹æ ¼å¼è¦æ±‚ã€‚

    Args:
        node (str): è¦éªŒè¯çš„èŠ‚ç‚¹å­—ç¬¦ä¸²ã€‚
        protocol (str): èŠ‚ç‚¹åè®®ï¼ˆhysteria2, vmess, trojan, ss, ssr, vlessï¼‰ã€‚

    Returns:
        tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯åŸå› )ã€‚
    """
    if protocol == "hysteria2":
        match = re.match(r"hysteria2:\/\/([^@]+)@([^:]+):(\d+)(?:\/|\?|$)", node)
        if not match:
            [cite_start]return False, "æ ¼å¼ä¸åŒ¹é…ï¼Œç¼ºå°‘ passwordã€host æˆ– port" [cite: 151]
        password, host, port = match.groups()
        if not password:
            [cite_start]return False, "password ä¸ºç©º" [cite: 151]
        if not is_valid_host(host):
            [cite_start]return False, f"æ— æ•ˆçš„ä¸»æœº: {host}" [cite: 151]
        if not is_valid_port(port):
            [cite_start]return False, f"æ— æ•ˆçš„ç«¯å£: {port}" [cite: 151]
        [cite_start]return True, "" [cite: 152]

    elif protocol == "vmess":
        if not node.startswith("vmess://"):
            [cite_start]return False, "ç¼ºå°‘ vmess:// å‰ç¼€" [cite: 152]
        try:
            # å°è¯•è§£ç ï¼Œå¿½ç•¥é Base64 å­—ç¬¦
            [cite_start]decoded = base64.b64decode(node[8:].strip('=').encode('ascii', 'ignore')).decode('utf-8', errors='ignore') [cite: 152]
            [cite_start]data = json.loads(decoded) [cite: 152]
            [cite_start]required_fields = {'v', 'ps', 'add', 'port', 'id', 'aid', 'net'} [cite: 153]
            if not all(field in data for field in required_fields):
                [cite_start]return False, f"ç¼ºå°‘å¿…è¦å­—æ®µ: {required_fields - set(data.keys())}" [cite: 153]
            if not is_valid_host(data['add']):
                [cite_start]return False, f"æ— æ•ˆçš„ä¸»æœº: {data['add']}" [cite: 153]
            if not is_valid_port(str(data['port'])):
                [cite_start]return False, f"æ— æ•ˆçš„ç«¯å£: {data['port']}" [cite: 154]
            if not is_valid_uuid(data['id']):
                [cite_start]return False, f"æ— æ•ˆçš„ UUID: {data['id']}" [cite: 154]
            if not str(data['aid']).isdigit():
                [cite_start]return False, f"æ— æ•ˆçš„ alterId: {data['aid']}" [cite: 154]
            if data['net'] not in {'tcp', 'ws', 'h2', 'grpc', 'kcp'}: # æ·»åŠ  kcp ç­‰å¸¸è§ç½‘ç»œç±»å‹
                [cite_start]return False, f"æ— æ•ˆçš„ç½‘ç»œç±»å‹: {data['net']}" [cite: 155]
            [cite_start]return True, "" [cite: 155]
        except (base64.binascii.Error, json.JSONDecodeError, UnicodeDecodeError, ValueError) as e:
            [cite_start]return False, f"Base64 è§£ç æˆ– JSON è§£æå¤±è´¥: {e}" [cite: 155]

    elif protocol == "trojan":
        match = re.match(r"trojan:\/\/([^@]+)@([^:]+):(\d+)(?:\/|\?|$)", node)
        if not match:
            [cite_start]return False, "æ ¼å¼ä¸åŒ¹é…ï¼Œç¼ºå°‘ passwordã€host æˆ– port" [cite: 156]
        [cite_start]password, host, port = match.groups() [cite: 156]
        if not password:
            [cite_start]return False, "password ä¸ºç©º" [cite: 156]
        if not is_valid_host(host):
            [cite_start]return False, f"æ— æ•ˆçš„ä¸»æœº: {host}" [cite: 156]
        if not is_valid_port(port):
            [cite_start]return False, f"æ— æ•ˆçš„ç«¯å£: {port}" [cite: 157]
        [cite_start]return True, "" [cite: 157]

    elif protocol == "ss":
        # ç®€åŒ– SS åŒ¹é…ï¼Œä¼˜å…ˆå¤„ç† Base64 è§£ç åçš„æ ¼å¼
        if node.startswith("ss://"):
            try:
                # å°è¯•è§£ç  Base64 éƒ¨åˆ†
                [cite_start]encoded_part = node[5:].split('#')[0].strip('=') [cite: 157]
                # ç¡®ä¿åªåŒ…å« Base64 å®‰å…¨å­—ç¬¦ï¼Œå¿½ç•¥å…¶ä»–
                [cite_start]encoded_part_ascii = encoded_part.encode('ascii', 'ignore') [cite: 158]
                [cite_start]decoded = base64.b64decode(encoded_part_ascii).decode('utf-8', errors='ignore') [cite: 158]

                [cite_start]match = re.match(r"([a-zA-Z0-9\-_]+):([^@]+)@([^:]+):(\d+)", decoded) [cite: 158]
                if not match:
                    [cite_start]return False, "Base64 è§£ç åæ ¼å¼ä¸åŒ¹é…" [cite: 159]
                
                [cite_start]method, password, host, port = match.groups() [cite: 159]
                if method not in SS_METHODS:
                    [cite_start]return False, f"ä¸æ”¯æŒçš„åŠ å¯†æ–¹æ³•: {method}" [cite: 159]
                if not password:
                    [cite_start]return False, "password ä¸ºç©º" [cite: 160]
                if not is_valid_host(host):
                    [cite_start]return False, f"æ— æ•ˆçš„ä¸»æœº: {host}" [cite: 160]
                if not is_valid_port(port):
                    [cite_start]return False, f"æ— æ•ˆçš„ç«¯å£: {port}" [cite: 161]
                [cite_start]return True, "" [cite: 161]
            except (base64.binascii.Error, UnicodeDecodeError, ValueError) as e:
                [cite_start]return False, f"Base64 è§£ç å¤±è´¥æˆ–æ ¼å¼é”™è¯¯: {e}" [cite: 161]
        [cite_start]return False, "ç¼ºå°‘ ss:// å‰ç¼€" # å¦‚æœæ²¡æœ‰ ss:// å‰ç¼€ï¼Œåˆ™è®¤ä¸ºä¸æ˜¯ SS èŠ‚ç‚¹ [cite: 161]

    elif protocol == "ssr":
        if not node.startswith("ssr://"):
            [cite_start]return False, "ç¼ºå°‘ ssr:// å‰ç¼€" [cite: 162]
        try:
            # å°è¯•è§£ç ï¼Œå¿½ç•¥é Base64 å­—ç¬¦
            [cite_start]decoded = base64.b64decode(node[6:].strip('=').encode('ascii', 'ignore')).decode('utf-8', errors='ignore') [cite: 162]
            [cite_start]parts = decoded.split(':') [cite: 162]
            if len(parts) < 6:
                [cite_start]return False, "æ ¼å¼ä¸åŒ¹é…ï¼Œç¼ºå°‘å¿…è¦å­—æ®µ" [cite: 163]
            
            [cite_start]host, port, protocol_ssr, method, obfs, password_encoded = parts[:6] # ä¿®æ”¹å˜é‡åä»¥é¿å…å†²çª [cite: 163]
            
            if not is_valid_host(host):
                [cite_start]return False, f"æ— æ•ˆçš„ä¸»æœº: {host}" [cite: 163]
            if not is_valid_port(port):
                [cite_start]return False, f"æ— æ•ˆçš„ç«¯å£: {port}" [cite: 164]
            if protocol_ssr not in SSR_PROTOCOLS:
                [cite_start]return False, f"ä¸æ”¯æŒçš„åè®®: {protocol_ssr}" [cite: 164]
            if method not in SS_METHODS:
                [cite_start]return False, f"ä¸æ”¯æŒçš„åŠ å¯†æ–¹æ³•: {method}" [cite: 164]
            if obfs not in SSR_OBFS:
                [cite_start]return False, f"ä¸æ”¯æŒçš„æ··æ·†: {obfs}" [cite: 165]
            
            try:
                # SSR çš„å¯†ç éƒ¨åˆ†æœ¬èº«å¯èƒ½æ˜¯ Base64 ç¼–ç çš„
                [cite_start]decoded_password = base64.b64decode(password_encoded.encode('ascii', 'ignore')).decode('utf-8', errors='ignore') [cite: 165]
                if not decoded_password: # å¯†ç ä¸ºç©ºä¹Ÿè§†ä¸ºæ— æ•ˆ
                    [cite_start]return False, "password ä¸ºç©ºæˆ–è§£ç åä¸ºç©º" [cite: 166]
            except (base64.binascii.Error, UnicodeDecodeError, ValueError):
                # å¦‚æœå¯†ç éƒ¨åˆ†ä¸æ˜¯ Base64 ç¼–ç ï¼Œæˆ–è€…è§£ç å¤±è´¥ï¼Œåˆ™ç›´æ¥ä½¿ç”¨åŸå§‹å¯†ç éƒ¨åˆ†
                if not password_encoded:
                    [cite_start]return False, "password ä¸ºç©º" [cite: 167]
            
            [cite_start]return True, "" [cite: 167]
        except (base64.binascii.Error, UnicodeDecodeError, ValueError) as e:
            [cite_start]return False, f"Base64 è§£ç å¤±è´¥: {e}" [cite: 167]

    elif protocol == "vless":
        match = re.match(r"vless:\/\/([0-9a-fA-F\-]+)@([^:]+):(\d+)(?:\/|\?|$)", node)
        if not match:
            [cite_start]return False, "æ ¼å¼ä¸åŒ¹é…ï¼Œç¼ºå°‘ uuidã€host æˆ– port" [cite: 168]
        [cite_start]uuid_str, host, port = match.groups() [cite: 168]
        if not is_valid_uuid(uuid_str):
            [cite_start]return False, f"æ— æ•ˆçš„ UUID: {uuid_str}" [cite: 168]
        if not is_valid_host(host):
            [cite_start]return False, f"æ— æ•ˆçš„ä¸»æœº: {host}" [cite: 168]
        if not is_valid_port(port):
            [cite_start]return False, f"æ— æ•ˆçš„ç«¯å£: {port}" [cite: 168]
        [cite_start]return True, "" [cite: 168]

    [cite_start]return False, "æœªçŸ¥åè®®" [cite: 169]

async def clean_old_cache_files(cleanup_threshold_hours: int):
    """
    æ¸…ç† data/cache ç›®å½•ä¸­è¿‡æœŸçš„æˆ–ä¸å†ä½¿ç”¨çš„ç¼“å­˜æ–‡ä»¶ã€‚
    åˆ é™¤ä¿®æ”¹æ—¶é—´æ—©äºæŒ‡å®šé˜ˆå€¼çš„æ–‡ä»¶ã€‚
    
    Args:
        cleanup_threshold_hours (int): ç¼“å­˜æ–‡ä»¶æ¸…ç†çš„é˜ˆå€¼ï¼ˆå°æ—¶ï¼‰ã€‚
    """
    now = datetime.datetime.now()
    cutoff_time = now - datetime.timedelta(hours=cleanup_threshold_hours)
    
    [cite_start]logging.info(f"å¼€å§‹æ¸…ç†ç¼“å­˜ç›®å½•: {CACHE_DIR}ï¼Œå°†åˆ é™¤ä¿®æ”¹æ—¶é—´æ—©äº {cutoff_time} çš„æ–‡ä»¶ã€‚") [cite: 169]
    
    deleted_count = 0
    try:
        for filename in os.listdir(CACHE_DIR):
            [cite_start]file_path = os.path.join(CACHE_DIR, filename) [cite: 170]
            if os.path.isfile(file_path):
                try:
                    [cite_start]file_mtime = datetime.datetime.fromtimestamp(os.path.getmtime(file_path)) [cite: 170]
                    if file_mtime < cutoff_time:
                        [cite_start]os.remove(file_path) [cite: 171]
                        [cite_start]logging.debug(f"å·²åˆ é™¤è¿‡æœŸç¼“å­˜æ–‡ä»¶: {filename}") [cite: 171]
                        [cite_start]deleted_count += 1 [cite: 171]
                except OSError as e:
                    [cite_start]logging.warning(f"æ— æ³•åˆ é™¤æ–‡ä»¶ {file_path}: {e}") [cite: 171]
        [cite_start]logging.info(f"ç¼“å­˜æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶ã€‚") [cite: 172]
    except FileNotFoundError:
        [cite_start]logging.info(f"ç¼“å­˜ç›®å½• {CACHE_DIR} ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†ã€‚") [cite: 172]
    except Exception as e:
        [cite_start]logging.error(f"æ¸…ç†ç¼“å­˜æ—¶å‘ç”Ÿé”™è¯¯: {e}") [cite: 172]

async def _fetch_url_with_retry(client: httpx.AsyncClient, url: str, headers: dict, original_protocol_url: str) -> httpx.Response | None:
    """
    å°è¯•ä» URL è·å–å†…å®¹ï¼Œå¹¶æ”¯æŒ HTTP åˆ° HTTPS çš„å›é€€ã€‚
    
    Args:
        client (httpx.AsyncClient): HTTP å®¢æˆ·ç«¯ã€‚
        url (str): è¦è·å–çš„ URLã€‚
        headers (dict): HTTP è¯·æ±‚å¤´ã€‚
        original_protocol_url (str): åˆå§‹è¯·æ±‚çš„ URLï¼Œç”¨äºé¿å…æ— é™å›é€€ã€‚
        
    Returns:
        httpx.Response | None: HTTP å“åº”å¯¹è±¡ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    try:
        [cite_start]logging.info(f"å°è¯•ä» {url.split('://')[0].upper()} è·å–å†…å®¹: {url} (User-Agent: {headers.get('User-Agent', 'N/A')})") [cite: 174]
        [cite_start]response = await client.get(url, headers=headers) [cite: 174]
        [cite_start]response.raise_for_status() [cite: 174]
        [cite_start]return response [cite: 174]
    # æ•è·æ›´é€šç”¨çš„ httpx.RequestError
    except httpx.RequestError as e:
        [cite_start]logging.warning(f"è¯·æ±‚ {url} æ—¶å‘ç”Ÿç½‘ç»œæˆ–è¿æ¥é”™è¯¯: {e}") [cite: 174]
        # å¦‚æœæ˜¯ HTTPS é”™è¯¯ï¼Œå°è¯•ç¦ç”¨ SSL éªŒè¯
        if isinstance(e, httpx.ConnectError) and "SSL" in str(e):
            [cite_start]logging.info(f"SSL è¿æ¥é”™è¯¯ï¼Œå°è¯•ç¦ç”¨ SSL éªŒè¯: {url}") [cite: 175]
            async with httpx.AsyncClient(timeout=10, verify=False, follow_redirects=True) as retry_client:
                try:
                    [cite_start]response = await retry_client.get(url, headers=headers) [cite: 175]
                    [cite_start]response.raise_for_status() [cite: 175]
                    [cite_start]return response [cite: 176]
                except httpx.HTTPStatusError as e_retry:
                    [cite_start]logging.error(f"ç¦ç”¨ SSL éªŒè¯åï¼Œè·å– {url} æ—¶å‘ç”Ÿ HTTP çŠ¶æ€é”™è¯¯: {e_retry}") [cite: 176]
                except httpx.RequestError as e_retry:
                    [cite_start]logging.error(f"ç¦ç”¨ SSL éªŒè¯åï¼Œè·å– {url} æ—¶å‘ç”Ÿç½‘ç»œè¯·æ±‚é”™è¯¯: {e_retry}") [cite: 176]
        # å¦‚æœæ˜¯ HTTP åˆ° HTTPS çš„å›é€€ï¼ˆä½†ä»…åœ¨åŸå§‹è¯·æ±‚æ˜¯ HTTP æ—¶æ‰å°è¯•ï¼‰
        elif url.startswith("http://") and original_protocol_url.startswith("http://"):
            [cite_start]https_url = url.replace("http://", "https://") [cite: 177]
            [cite_start]logging.info(f"å°è¯•ä» HTTPS å›é€€è·å–å†…å®¹: {https_url}") [cite: 177]
            try:
                [cite_start]fallback_headers = dict(headers) [cite: 178]
                [cite_start]fallback_headers.pop('If-None-Match', None) [cite: 178]
                [cite_start]fallback_headers.pop('If-Modified-Since', None) [cite: 178]
                [cite_start]response_https = await client.get(https_url, headers=fallback_headers) [cite: 178]
                [cite_start]response_https.raise_for_status() [cite: 178]
                [cite_start]return response_https [cite: 178]
            except httpx.HTTPStatusError as e_https:
                [cite_start]logging.error(f"è·å– {https_url} æ—¶å‘ç”Ÿ HTTPS çŠ¶æ€é”™è¯¯: {e_https}") [cite: 179]
            except httpx.RequestError as e_https:
                [cite_start]logging.error(f"è·å– {https_url} æ—¶å‘ç”Ÿ HTTPS ç½‘ç»œè¯·æ±‚é”™è¯¯: {e_https}") [cite: 179]
        else:
            [cite_start]logging.error(f"è·å– {url} æ—¶å‘ç”ŸæœªçŸ¥ç½‘ç»œé”™è¯¯: {e}") [cite: 179]
    except httpx.HTTPStatusError as e:
        [cite_start]logging.error(f"è·å– {url} æ—¶å‘ç”Ÿ HTTP çŠ¶æ€é”™è¯¯: {e}") [cite: 179]
        # è¿™é‡Œç§»é™¤ HTTP åˆ° HTTPS çš„å›é€€é€»è¾‘ï¼Œå› ä¸ºå®ƒå·²ç»åœ¨ RequestError ä¸­å¤„ç†
        # é¿å…é‡å¤å°è¯•æˆ–é€»è¾‘æ··ä¹±
    except Exception as e:
        [cite_start]logging.error(f"è·å– {url} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}") [cite: 181]
    return None

async def get_url_content(url: str, use_cache: bool = True) -> str | None:
    """
    ä» URL è·å–å†…å®¹ï¼Œå¹¶æ”¯æŒåŸºäº HTTP å¤´éƒ¨çš„ç¼“å­˜éªŒè¯ã€‚
    
    Args:
        url (str): è¦è·å–çš„ URLã€‚
        use_cache (bool): æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼Œé»˜è®¤ Trueã€‚
        
    Returns:
        str | None: è·å–çš„å†…å®¹å­—ç¬¦ä¸²ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    [cite_start]cache_entry_path = os.path.join(CACHE_DIR, hashlib.md5(url.encode()).hexdigest() + ".json") [cite: 181]
    
    cached_data = None
    if use_cache and os.path.exists(cache_entry_path):
        try:
            async with aiofiles.open(cache_entry_path, 'r', encoding='utf-8') as f:
                [cite_start]cached_data = json.loads(await f.read()) [cite: 182]
            
            [cite_start]cache_timestamp_str = cached_data.get('timestamp', datetime.datetime.min.isoformat()) [cite: 182]
            [cite_start]cache_timestamp = datetime.datetime.fromisoformat(cache_timestamp_str) [cite: 182]
            [cite_start]if (datetime.datetime.now() - cache_timestamp).total_seconds() / 3600 >= CACHE_EXPIRATION_HOURS: [cite: 183]
                [cite_start]logging.info(f"ç¼“å­˜ {url} å·²è¿‡æœŸï¼ˆè¶…è¿‡ {CACHE_EXPIRATION_HOURS} å°æ—¶ï¼‰ï¼Œå°†é‡æ–°æ£€æŸ¥æ›´æ–°ã€‚") [cite: 183]
                cached_data = None
            else:
                [cite_start]logging.info(f"ç¼“å­˜ {url} æœ‰æ•ˆï¼Œå°è¯•ä½¿ç”¨ç¼“å­˜è¿›è¡Œæ¡ä»¶è¯·æ±‚ã€‚") [cite: 183]
        except (json.JSONDecodeError, KeyError, FileNotFoundError) as e:
            [cite_start]logging.warning(f"è¯»å–æˆ–è§£æç¼“å­˜æ–‡ä»¶ {cache_entry_path} å¤±è´¥: {e}ï¼Œå°†é‡æ–°è·å–ã€‚") [cite: 183]
            [cite_start]cached_data = None [cite: 184]

    async with httpx.AsyncClient(timeout=10, verify=True, follow_redirects=True) as client:
        headers_for_request = {
            [cite_start]"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36" [cite: 185]
        }

        if cached_data:
            if cached_data.get('etag'):
                [cite_start]headers_for_request['If-None-Match'] = cached_data['etag'] [cite: 185]
            if cached_data.get('last-modified'):
                [cite_start]headers_for_request['If-Modified-Since'] = cached_data['last-modified'] [cite: 185]

        [cite_start]response = await _fetch_url_with_retry(client, url, headers_for_request, url) [cite: 186]

        if response:
            if response.status_code == 304 and cached_data and cached_data.get('content'):
                [cite_start]logging.info(f"URL: {url} å†…å®¹æœªæ›´æ–° (304 Not Modified)ï¼Œä»ç¼“å­˜è¯»å–ã€‚") [cite: 186]
                [cite_start]return base64.b64decode(cached_data['content']).decode('utf-8', errors='ignore') [cite: 186]
            else:
                [cite_start]content = response.text [cite: 186]
                new_cached_data = {
                    [cite_start]"content": base64.b64encode(content.encode('utf-8')).decode('ascii'), [cite: 187]
                    [cite_start]"timestamp": datetime.datetime.now().isoformat() [cite: 187]
                }
                if 'etag' in response.headers:
                    [cite_start]new_cached_data['etag'] = response.headers['etag'] [cite: 188]
                if 'last-modified' in response.headers:
                    [cite_start]new_cached_data['last-modified'] = response.headers['last-modified'] [cite: 188]

                try:
                    async with aiofiles.open(cache_entry_path, 'w', encoding='utf-8') as f:
                        [cite_start]await f.write(json.dumps(new_cached_data, ensure_ascii=False)) [cite: 189]
                    [cite_start]logging.info(f"URL: {url} å†…å®¹å·²æ›´æ–°ï¼Œå·²å†™å…¥ç¼“å­˜ã€‚") [cite: 189]
                except (IOError, json.JSONEncodeError) as e:
                    [cite_start]logging.error(f"å†™å…¥ç¼“å­˜æ–‡ä»¶ {cache_entry_path} å¤±è´¥: {e}") [cite: 189]
                
                [cite_start]return content [cite: 190]
        else:
            [cite_start]logging.warning(f"æ— æ³•è·å– URL: {url} çš„å†…å®¹ï¼Œè·³è¿‡è¯¥ URL çš„èŠ‚ç‚¹æå–ã€‚") [cite: 190]
            [cite_start]return None [cite: 190]

async def extract_nodes_from_content(url: str, content: str) -> list[str]:
    """
    ä»æ–‡æœ¬å†…å®¹ä¸­æå–ç¬¦åˆ Vmess, Trojan, SS, SSR, Vless, Hysteria2 æ ¼å¼çš„èŠ‚ç‚¹ï¼Œå¹¶éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚
    
    Args:
        url (str): æº URLï¼Œç”¨äºæ—¥å¿—è®°å½•ã€‚
        content (str): è¦è§£æçš„å†…å®¹ã€‚
        
    Returns:
        list[str]: æå–çš„å”¯ä¸€æœ‰æ•ˆèŠ‚ç‚¹åˆ—è¡¨ã€‚
    """
    unique_nodes = set()
    
    # å°è¯• Base64 è§£ç ï¼Œä½†è¦ç¡®ä¿è¾“å…¥æ˜¯æœ‰æ•ˆçš„ Base64 å­—ç¬¦ä¸²
    decoded_content_attempt = None
    # æ£€æŸ¥å†…å®¹æ˜¯å¦å¯èƒ½ä¸º Base64ï¼Œè¿‡æ»¤æ‰é Base64 å­—ç¬¦
    if re.fullmatch(r"^[a-zA-Z0-9\-_+=/\s]+$", content.strip()): # å…è®¸ç©ºæ ¼ï¼Œå› ä¸ºæŸäº›è®¢é˜…é“¾æ¥å¯èƒ½æ˜¯å¤šè¡ŒBase64
        try:
            # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦å¹¶ç¡®ä¿é•¿åº¦æ˜¯4çš„å€æ•°
            [cite_start]clean_content = content.strip().replace(" ", "").replace("\n", "").replace("\r", "") [cite: 192]
            padding_needed = len(clean_content) % 4
            if padding_needed != 0:
                [cite_start]clean_content += '=' * (4 - padding_needed) [cite: 192]
            
            [cite_start]decoded_content_attempt = base64.b64decode(clean_content).decode('utf-8', errors='ignore') [cite: 192]
            [cite_start]logging.debug(f"æˆåŠŸ Base64 è§£ç å†…å®¹ (URL: {url})") [cite: 193]
        except (base64.binascii.Error, UnicodeDecodeError, ValueError) as e:
            [cite_start]logging.debug(f"Base64 è§£ç å¤±è´¥ (URL: {url}): {e}") [cite: 193]
            pass # ä¸æ˜¯æœ‰æ•ˆçš„ Base64ï¼Œç»§ç»­æŒ‰åŸå§‹æ–‡æœ¬å¤„ç†

    contents_to_search = [content]
    if decoded_content_attempt and decoded_content_attempt != content: # é¿å…é‡å¤æœç´¢
        [cite_start]contents_to_search.append(decoded_content_attempt) [cite: 193]

    for text_content in contents_to_search:
        # å°è¯•è§£æ JSON
        try:
            [cite_start]json_data = json.loads(text_content) [cite: 194]
            if isinstance(json_data, list):
                for item in json_data:
                    if isinstance(item, dict) and 'v' in item and 'ps' in item and 'add' in item:
                        [cite_start]vmess_node = "vmess://" + base64.b64encode(json.dumps(item, separators=(',', ':')).encode()).decode() [cite: 195]
                        [cite_start]is_valid, reason = validate_node(vmess_node, "vmess") [cite: 195]
                        if is_valid:
                            [cite_start]unique_nodes.add(vmess_node) [cite: 195]
                        else:
                            [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ Vmess èŠ‚ç‚¹ (URL: {url}, JSON åˆ—è¡¨): {vmess_node}, åŸå› : {reason}") [cite: 196]
            elif isinstance(json_data, dict):
                # å¤„ç† V2RayN/Clash config æ ¼å¼
                [cite_start]if 'outbounds' in json_data and isinstance(json_data['outbounds'], list): [cite: 197]
                    for outbound in json_data['outbounds']:
                        if outbound.get('protocol') == 'vmess' and outbound.get('settings', {}).get('vnext'):
                            # Vmess èŠ‚ç‚¹é€šå¸¸åœ¨ vnext[0].users[0]
                            [cite_start]server_settings = outbound['settings']['vnext'][0] [cite: 198]
                            [cite_start]user_settings = server_settings['users'][0] [cite: 198]
                            vmess_config = {
                                [cite_start]"v": "2", [cite: 199]
                                [cite_start]"ps": outbound.get('tag', 'node'), # ä½¿ç”¨ tag æˆ–é»˜è®¤å [cite: 199]
                                [cite_start]"add": server_settings.get('address'), [cite: 199]
                                [cite_start]"port": server_settings.get('port'), [cite: 200]
                                [cite_start]"id": user_settings.get('id'), [cite: 200]
                                [cite_start]"aid": user_settings.get('alterId', '0'), [cite: 200]
                                [cite_start]"net": outbound.get('streamSettings', {}).get('network', 'tcp'), [cite: 201]
                                [cite_start]"type": outbound.get('streamSettings', {}).get('type', ''), [cite: 201]
                                [cite_start]"host": outbound.get('streamSettings', {}).get('wsSettings', {}).get('headers', {}).get('Host', ''), [cite: 201]
                                [cite_start]"path": outbound.get('streamSettings', {}).get('wsSettings', {}).get('path', ''), [cite: 202]
                                [cite_start]"tls": "tls" if outbound.get('streamSettings', {}).get('security') == 'tls' else "" [cite: 202]
                            }
                            [cite_start]vmess_config = {k: v for k, v in vmess_config.items() if v is not None and v != ''} [cite: 203]
                            [cite_start]vmess_str = "vmess://" + base64.b64encode(json.dumps(vmess_config, separators=(',', ':')).encode()).decode() [cite: 203]
                            [cite_start]is_valid, reason = validate_node(vmess_str, "vmess") [cite: 204]
                            if is_valid:
                                [cite_start]unique_nodes.add(vmess_str) [cite: 204]
                            else:
                                [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ Vmess èŠ‚ç‚¹ (URL: {url}, V2Ray é…ç½®): {vmess_str}, åŸå› : {reason}") [cite: 205]
                        elif outbound.get('protocol') == 'trojan' and outbound.get('settings', {}).get('servers'):
                            [cite_start]server_settings = outbound['settings']['servers'][0] [cite: 206]
                            [cite_start]trojan_node = f"trojan://{server_settings.get('password')}@{server_settings.get('address')}:{server_settings.get('port')}" [cite: 206]
                            if outbound.get('streamSettings', {}).get('security') == 'tls':
                                if server_settings.get('sni'):
                                    [cite_start]trojan_node += f"?sni={server_settings['sni']}" [cite: 207]
                                elif outbound.get('streamSettings', {}).get('tlsSettings', {}).get('serverName'):
                                    [cite_start]trojan_node += f"?sni={outbound['streamSettings']['tlsSettings']['serverName']}" [cite: 208]
                                # V2Ray config ä¸­æ²¡æœ‰ç›´æ¥çš„ allowInsecure å¯¹åº”ï¼Œè¿™é‡Œæš‚ä¸å¤„ç†
                            [cite_start]is_valid, reason = validate_node(trojan_node, "trojan") [cite: 208]
                            if is_valid:
                                [cite_start]unique_nodes.add(trojan_node) [cite: 209]
                            else:
                                [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ Trojan èŠ‚ç‚¹ (URL: {url}, V2Ray é…ç½®): {trojan_node}, åŸå› : {reason}") [cite: 210]
                
                # å¤„ç† Clash/Sing-Box proxies æ ¼å¼
                [cite_start]elif 'proxies' in json_data and isinstance(json_data['proxies'], list): [cite: 210]
                    for proxy in json_data['proxies']:
                        if proxy.get('type') == 'vmess':
                            vmess_node = {
                                [cite_start]"v": "2", [cite: 212]
                                [cite_start]"ps": proxy.get('name', 'node'), [cite: 212]
                                [cite_start]"add": proxy.get('server'), [cite: 212]
                                [cite_start]"port": proxy.get('port'), [cite: 213]
                                [cite_start]"id": proxy.get('uuid'), [cite: 213]
                                [cite_start]"aid": proxy.get('alterId', '0'), [cite: 213]
                                [cite_start]"net": proxy.get('network', 'tcp'), [cite: 213]
                                [cite_start]"type": "", # Clash é…ç½®ä¸­å¯èƒ½æ²¡æœ‰ç›´æ¥çš„ type å­—æ®µ [cite: 214]
                                [cite_start]"host": proxy.get('ws-headers', {}).get('Host', '') or proxy.get('tls-host', ''), # å…¼å®¹ä¸åŒå­—æ®µ [cite: 214]
                                [cite_start]"path": proxy.get('ws-path', ''), [cite: 214]
                                [cite_start]"tls": "tls" if proxy.get('tls', False) else "" [cite: 215]
                            }
                            [cite_start]vmess_node = {k: v for k, v in vmess_node.items() if v is not None and v != ''} [cite: 216]
                            [cite_start]vmess_str = "vmess://" + base64.b64encode(json.dumps(vmess_node, separators=(',', ':')).encode()).decode() [cite: 216]
                            [cite_start]is_valid, reason = validate_node(vmess_str, "vmess") [cite: 216]
                            if is_valid:
                                [cite_start]unique_nodes.add(vmess_str) [cite: 217]
                            else:
                                [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ Vmess èŠ‚ç‚¹ (URL: {url}, Clash/Sing-Box JSON): {vmess_str}, åŸå› : {reason}") [cite: 218]
                        elif proxy.get('type') == 'trojan':
                            [cite_start]trojan_node = f"trojan://{proxy.get('password')}@{proxy.get('server')}:{proxy.get('port')}" [cite: 218]
                            if proxy.get('sni'):
                                [cite_start]trojan_node += f"?sni={proxy['sni']}" [cite: 219]
                            if proxy.get('skip-cert-verify', False): # Clash çš„ skip-cert-verify
                                [cite_start]trojan_node += "&allowInsecure=1" [cite: 219]
                            [cite_start]is_valid, reason = validate_node(trojan_node, "trojan") [cite: 220]
                            if is_valid:
                                [cite_start]unique_nodes.add(trojan_node) [cite: 220]
                            else:
                                [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ Trojan èŠ‚ç‚¹ (URL: {url}, Clash/Sing-Box JSON): {trojan_node}, åŸå› : {reason}") [cite: 221]
                        elif proxy.get('type') == 'ss':
                            # Clash ss ç±»å‹è§£æ
                            [cite_start]ss_node_parts = [] [cite: 222]
                            [cite_start]method = proxy.get('cipher') [cite: 222]
                            [cite_start]password = proxy.get('password') [cite: 222]
                            [cite_start]server = proxy.get('server') [cite: 223]
                            [cite_start]port = proxy.get('port') [cite: 223]
                            if method and password and server and port:
                                # æ„å»º ss://base64encoded_info æ ¼å¼
                                [cite_start]ss_info = f"{method}:{password}@{server}:{port}" [cite: 224]
                                [cite_start]encoded_ss_info = base64.b64encode(ss_info.encode()).decode() [cite: 224]
                                [cite_start]ss_node = f"ss://{encoded_ss_info}" [cite: 225]
                                if proxy.get('name'):
                                    [cite_start]ss_node += f"#{proxy['name']}" [cite: 226]
                                
                                [cite_start]is_valid, reason = validate_node(ss_node, "ss") [cite: 226]
                                if is_valid:
                                    [cite_start]unique_nodes.add(ss_node) [cite: 227]
                                else:
                                    [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ SS èŠ‚ç‚¹ (URL: {url}, Clash JSON): {ss_node}, åŸå› : {reason}") [cite: 228]
                        elif proxy.get('type') == 'vless':
                            # Clash/Sing-Box vless ç±»å‹è§£æ
                            vless_node_config = {
                                [cite_start]"uuid": proxy.get('uuid'), [cite: 229]
                                [cite_start]"address": proxy.get('server'), [cite: 229]
                                [cite_start]"port": proxy.get('port'), [cite: 230]
                                [cite_start]"flow": proxy.get('flow'), [cite: 230]
                                [cite_start]"encryption": proxy.get('cipher', 'none'), [cite: 230]
                                [cite_start]"security": proxy.get('tls', False), [cite: 231]
                                [cite_start]"sni": proxy.get('sni'), [cite: 231]
                                [cite_start]"fingerprint": proxy.get('client-fingerprint'), [cite: 231]
                                [cite_start]"alpn": proxy.get('alpn'), [cite: 232]
                                [cite_start]"host": proxy.get('ws-headers', {}).get('Host', '') or proxy.get('xudp-header', {}).get('Host', ''), [cite: 232]
                                [cite_start]"path": proxy.get('ws-path', '') or proxy.get('grpc-path', ''), [cite: 232]
                                [cite_start]"mode": proxy.get('grpc-mode') [cite: 233]
                            }
                            # å°è¯•æ„å»º VLESS é“¾æ¥
                            # ğŸ‘‡ è¿™è¡Œæ˜¯åŸ 658 è¡Œï¼Œç°åœ¨ä¿®æ­£ç¼©è¿›
                            [cite_start]if vless_node_config.get('uuid') and vless_node_config.get('address') and vless_node_config.get('port'): [cite: 234]
                                [cite_start]vless_uri = f"vless://{vless_node_config['uuid']}@{vless_node_config['address']}:{vless_node_config['port']}" [cite: 234]
                                [cite_start]params = [] [cite: 235]
                                if vless_node_config.get('security'):
                                    [cite_start]params.append("security=tls") [cite: 235]
                                if vless_node_config.get('sni'):
                                    [cite_start]params.append(f"sni={vless_node_config['sni']}") [cite: 236]
                                if vless_node_config.get('flow'):
                                    [cite_start]params.append(f"flow={vless_node_config['flow']}") [cite: 236]
                                if vless_node_config.get('alpn'):
                                    [cite_start]params.append(f"alpn={','.join(vless_node_config['alpn'])}") [cite: 237]
                                if vless_node_config.get('fingerprint'):
                                    [cite_start]params.append(f"fp={vless_node_config['fingerprint']}") [cite: 238]
                                if vless_node_config.get('host'):
                                    [cite_start]params.append(f"host={vless_node_config['host']}") [cite: 238]
                                if vless_node_config.get('path'):
                                    [cite_start]params.append(f"path={vless_node_config['path']}") [cite: 239]
                                if vless_node_config.get('mode'):
                                    [cite_start]params.append(f"mode={vless_node_config['mode']}") [cite: 240]

                                if params:
                                    vless_uri += "?" + [cite_start]"&".join(params) [cite: 240]
                                
                                if proxy.get('name'):
                                    [cite_start]vless_uri += f"#{proxy['name']}" [cite: 242]

                                [cite_start]is_valid, reason = validate_node(vless_uri, "vless") [cite: 242]
                                if is_valid:
                                    [cite_start]unique_nodes.add(vless_uri) [cite: 243]
                                else:
                                    [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ VLESS èŠ‚ç‚¹ (URL: {url}, Clash/Sing-Box JSON): {vless_uri}, åŸå› : {reason}") [cite: 243]
                
        except json.JSONDecodeError:
            pass # ä¸æ˜¯ JSON æ ¼å¼ï¼Œå¿½ç•¥
        except Exception as e:
            [cite_start]logging.warning(f"JSON è§£ææˆ–å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯ (URL: {url}): {e}") [cite: 244]

        # å°è¯•è§£æ YAML
        try:
            [cite_start]yaml_data = yaml.safe_load(text_content) [cite: 245]
            [cite_start]if isinstance(yaml_data, dict) and 'proxies' in yaml_data and isinstance(yaml_data['proxies'], list): [cite: 245]
                for proxy in yaml_data['proxies']:
                    if proxy.get('type') == 'vmess':
                        vmess_node = {
                            [cite_start]"v": "2", [cite: 246]
                            [cite_start]"ps": proxy.get('name', 'node'), [cite: 246]
                            [cite_start]"add": proxy.get('server'), [cite: 246]
                            [cite_start]"port": proxy.get('port'), [cite: 247]
                            [cite_start]"id": proxy.get('uuid'), [cite: 247]
                            [cite_start]"aid": proxy.get('alterId', '0'), [cite: 247]
                            [cite_start]"net": proxy.get('network', 'tcp'), [cite: 247]
                            [cite_start]"type": "", [cite: 248]
                            [cite_start]"host": proxy.get('ws-headers', {}).get('Host', '') or proxy.get('tls-host', ''), [cite: 248]
                            [cite_start]"path": proxy.get('ws-path', ''), [cite: 248]
                            [cite_start]"tls": "tls" if proxy.get('tls', False) else "" [cite: 249]
                        }
                        [cite_start]vmess_node = {k: v for k, v in vmess_node.items() if v is not None and v != ''} [cite: 249]
                        [cite_start]vmess_str = "vmess://" + base64.b64encode(json.dumps(vmess_node, separators=(',', ':')).encode()).decode() [cite: 250]
                        [cite_start]is_valid, reason = validate_node(vmess_str, "vmess") [cite: 250]
                        if is_valid:
                            [cite_start]unique_nodes.add(vmess_str) [cite: 250]
                        else:
                            [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ Vmess èŠ‚ç‚¹ (URL: {url}, YAML): {vmess_str}, åŸå› : {reason}") [cite: 251]
                    elif proxy.get('type') == 'trojan':
                        [cite_start]trojan_node = f"trojan://{proxy.get('password')}@{proxy.get('server')}:{proxy.get('port')}" [cite: 252]
                        if proxy.get('sni'):
                            [cite_start]trojan_node += f"?sni={proxy['sni']}" [cite: 252]
                        if proxy.get('skip-cert-verify', False):
                            [cite_start]trojan_node += "&allowInsecure=1" [cite: 253]
                        [cite_start]is_valid, reason = validate_node(trojan_node, "trojan") [cite: 253]
                        if is_valid:
                            [cite_start]unique_nodes.add(trojan_node) [cite: 253]
                        else:
                            [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ Trojan èŠ‚ç‚¹ (URL: {url}, YAML): {trojan_node}, åŸå› : {reason}") [cite: 254]
                    elif proxy.get('type') == 'ss':
                        [cite_start]ss_node_parts = [] [cite: 255]
                        [cite_start]method = proxy.get('cipher') [cite: 255]
                        [cite_start]password = proxy.get('password') [cite: 255]
                        [cite_start]server = proxy.get('server') [cite: 255]
                        [cite_start]port = proxy.get('port') [cite: 256]
                        if method and password and server and port:
                            [cite_start]ss_info = f"{method}:{password}@{server}:{port}" [cite: 256]
                            [cite_start]encoded_ss_info = base64.b64encode(ss_info.encode()).decode() [cite: 257]
                            [cite_start]ss_node = f"ss://{encoded_ss_info}" [cite: 257]
                            if proxy.get('name'):
                                [cite_start]ss_node += f"#{proxy['name']}" [cite: 257]
                            
                            [cite_start]is_valid, reason = validate_node(ss_node, "ss") [cite: 258]
                            if is_valid:
                                [cite_start]unique_nodes.add(ss_node) [cite: 259]
                            else:
                                [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ SS èŠ‚ç‚¹ (URL: {url}, Clash YAML): {ss_node}, åŸå› : {reason}") [cite: 259]
                    elif proxy.get('type') == 'vless':
                        vless_node_config = {
                            [cite_start]"uuid": proxy.get('uuid'), [cite: 260]
                            [cite_start]"address": proxy.get('server'), [cite: 261]
                            [cite_start]"port": proxy.get('port'), [cite: 261]
                            [cite_start]"flow": proxy.get('flow'), [cite: 261]
                            [cite_start]"encryption": proxy.get('cipher', 'none'), [cite: 261]
                            [cite_start]"security": proxy.get('tls', False), [cite: 262]
                            [cite_start]"sni": proxy.get('sni'), [cite: 262]
                            [cite_start]"fingerprint": proxy.get('client-fingerprint'), [cite: 262]
                            [cite_start]"alpn": proxy.get('alpn'), [cite: 262]
                            [cite_start]"host": proxy.get('ws-headers', {}).get('Host', '') or proxy.get('xudp-header', {}).get('Host', ''), [cite: 263]
                            [cite_start]"path": proxy.get('ws-path', '') or proxy.get('grpc-path', ''), [cite: 263]
                            [cite_start]"mode": proxy.get('grpc-mode') [cite: 264]
                        }
                        # å°è¯•æ„å»º VLESS é“¾æ¥
                        # ğŸ‘‡ è¿™è¡Œæ˜¯åŸ YAML éƒ¨åˆ†å¯¹åº”çš„é”™è¯¯è¡Œï¼Œç°åœ¨ä¿®æ­£ç¼©è¿›
                        [cite_start]if vless_node_config.get('uuid') and vless_node_config.get('address') and vless_node_config.get('port'): [cite: 264]
                            [cite_start]vless_uri = f"vless://{vless_node_config['uuid']}@{vless_node_config['address']}:{vless_node_config['port']}" [cite: 264]
                            [cite_start]params = [] [cite: 265]
                            if vless_node_config.get('security'):
                                [cite_start]params.append("security=tls") [cite: 265]
                            if vless_node_config.get('sni'):
                                [cite_start]params.append(f"sni={vless_node_config['sni']}") [cite: 266]
                            if vless_node_config.get('flow'):
                                [cite_start]params.append(f"flow={vless_node_config['flow']}") [cite: 266]
                            if vless_node_config.get('alpn'):
                                [cite_start]params.append(f"alpn={','.join(vless_node_config['alpn'])}") [cite: 267]
                            if vless_node_config.get('fingerprint'):
                                [cite_start]params.append(f"fp={vless_node_config['fingerprint']}") [cite: 268]
                            if vless_node_config.get('host'):
                                [cite_start]params.append(f"host={vless_node_config['host']}") [cite: 268]
                            if vless_node_config.get('path'):
                                [cite_start]params.append(f"path={vless_node_config['path']}") [cite: 269]
                            if vless_node_config.get('mode'):
                                [cite_start]params.append(f"mode={vless_node_config['mode']}") [cite: 269]

                            if params:
                                vless_uri += "?" + [cite_start]"&".join(params) [cite: 270]
                            
                            if proxy.get('name'):
                                [cite_start]vless_uri += f"#{proxy['name']}" [cite: 271]

                            [cite_start]is_valid, reason = validate_node(vless_uri, "vless") [cite: 272]
                            if is_valid:
                                [cite_start]unique_nodes.add(vless_uri) [cite: 272]
                            else:
                                [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ VLESS èŠ‚ç‚¹ (URL: {url}, Clash YAML): {vless_uri}, åŸå› : {reason}") [cite: 273]

        except yaml.YAMLError:
            pass # ä¸æ˜¯ YAML æ ¼å¼ï¼Œå¿½ç•¥
        except Exception as e:
            [cite_start]logging.warning(f"YAML è§£ææˆ–å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯ (URL: {url}): {e}") [cite: 273]

        # ç›´æ¥ä»æ–‡æœ¬å†…å®¹ä¸­åŒ¹é…æ‰€æœ‰åè®®
        for protocol, pattern in NODE_PATTERNS.items():
            [cite_start]for match in re.finditer(pattern, text_content): [cite: 274]
                [cite_start]node = match.group(0) [cite: 274]
                [cite_start]is_valid, reason = validate_node(node, protocol) [cite: 274]
                if is_valid:
                    [cite_start]unique_nodes.add(node) [cite: 274]
                else:
                    [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ {protocol} èŠ‚ç‚¹ (URL: {url}, ç›´æ¥åŒ¹é…): {node}, åŸå› : {reason}") [cite: 275]

    # å¤„ç† HTML å†…å®¹
    if "<html" in content.lower() or "<!doctype html>" in content.lower():
        [cite_start]soup = BeautifulSoup(content, 'html.parser') [cite: 275]
        # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
        for text_element in soup.find_all(string=True):
            [cite_start]text = str(text_element) [cite: 276]
            # åœ¨ HTML æ–‡æœ¬ä¸­ç›´æ¥åŒ¹é…èŠ‚ç‚¹
            for protocol, pattern in NODE_PATTERNS.items():
                for match in re.finditer(pattern, text):
                    [cite_start]node = match.group(0) [cite: 276]
                    [cite_start]is_valid, reason = validate_node(node, protocol) [cite: 276]
                    if is_valid:
                        [cite_start]unique_nodes.add(node) [cite: 277]
                    else:
                        [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ {protocol} èŠ‚ç‚¹ (URL: {url}, HTML æ–‡æœ¬): {node}, åŸå› : {reason}") [cite: 277]
            
            # åœ¨ HTML æ–‡æœ¬ä¸­å¯»æ‰¾å¯èƒ½çš„ Base64 ç¼–ç çš„èŠ‚ç‚¹
            for word_match in re.finditer(r'\b[A-Za-z0-9+/]{20,}=*\b', text): # åŒ¹é…å¯èƒ½åŒ…å«Base64çš„å•è¯
                [cite_start]word = word_match.group(0) [cite: 278]
                padding_needed = len(word) % 4
                if padding_needed != 0:
                    [cite_start]word += '=' * (4 - padding_needed) # æ·»åŠ å¡«å…… [cite: 279]

                try:
                    # å°è¯• Base64 è§£ç 
                    [cite_start]decoded_text = base64.b64decode(word.encode('ascii', 'ignore')).decode('utf-8', errors='ignore') [cite: 279]
                    for protocol, pattern in NODE_PATTERNS.items():
                        [cite_start]for match in re.finditer(pattern, decoded_text): [cite: 280]
                            [cite_start]node = match.group(0) [cite: 280]
                            [cite_start]is_valid, reason = validate_node(node, protocol) [cite: 280]
                            if is_valid:
                                [cite_start]unique_nodes.add(node) [cite: 281]
                            else:
                                [cite_start]logging.debug(f"ä¸¢å¼ƒæ— æ•ˆ {protocol} èŠ‚ç‚¹ (URL: {url}, HTML Base64): {node}, åŸå› : {reason}") [cite: 282]
                except (base64.binascii.Error, UnicodeDecodeError, ValueError) as e:
                    [cite_start]logging.debug(f"HTML å†…å®¹ä¸­çš„ Base64 è§£ç å¤±è´¥æˆ–æ— æ•ˆ: {word}, é”™è¯¯: {e}") [cite: 282]
                    pass # é Base64 å­—ç¬¦ä¸²ï¼Œå¿½ç•¥

    [cite_start]return list(unique_nodes) [cite: 282]

async def process_url(url: str, all_nodes_writer: aiofiles.threadpool.text.AsyncTextIOWrapper, semaphore: asyncio.Semaphore):
    """
    å¤„ç†å•ä¸ª URLï¼Œè·å–å†…å®¹ï¼Œæå–èŠ‚ç‚¹å¹¶å†™å…¥æ–‡ä»¶ã€‚
    
    Args:
        url (str): è¦å¤„ç†çš„ URLã€‚
        all_nodes_writer: å¼‚æ­¥æ–‡ä»¶å†™å…¥å¯¹è±¡ï¼Œç”¨äºå†™å…¥æ‰€æœ‰èŠ‚ç‚¹ã€‚
        semaphore (asyncio.Semaphore): å¹¶å‘æ§åˆ¶ä¿¡å·é‡ã€‚
        
    Returns:
        tuple[str, int]: URL å’Œæå–çš„èŠ‚ç‚¹æ•°é‡ã€‚
    """
    async with semaphore:
        [cite_start]logging.info(f"å¼€å§‹å¤„ç† URL: {url}") [cite: 284]
        [cite_start]content = await get_url_content(url) [cite: 284]

        if not content:
            [cite_start]logging.warning(f"æ— æ³•è·å– {url} çš„å†…å®¹ï¼Œè·³è¿‡è¯¥ URL çš„èŠ‚ç‚¹æå–ã€‚") [cite: 284]
            [cite_start]return url, 0 [cite: 284]

        [cite_start]logging.info(f"å¼€å§‹è§£æ {url} çš„å†…å®¹...") [cite: 284]
        [cite_start]unique_nodes = await extract_nodes_from_content(url, content) [cite: 284]
        [cite_start]logging.info(f"å®Œæˆè§£æ {url} çš„å†…å®¹ã€‚æå–åˆ° {len(unique_nodes)} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹ã€‚") [cite: 284]

        # å°†æå–åˆ°çš„èŠ‚ç‚¹å†™å…¥ä»¥ URL MD5 å‘½åçš„æ–‡ä»¶
        [cite_start]safe_url_name = hashlib.md5(url.encode()).hexdigest() [cite: 285]
        [cite_start]url_output_file = os.path.join(DATA_DIR, f"{safe_url_name}.txt") [cite: 285]
        try:
            async with aiofiles.open(url_output_file, 'w', encoding='utf-8') as f:
                for node in unique_nodes:
                    [cite_start]await f.write(f"{node}\n") [cite: 285]
            [cite_start]logging.info(f"URL: {url} çš„èŠ‚ç‚¹å·²ä¿å­˜åˆ° {url_output_file}") [cite: 285]
        except IOError as e:
            [cite_start]logging.error(f"å†™å…¥ URL èŠ‚ç‚¹æ–‡ä»¶ {url_output_file} å¤±è´¥: {e}") [cite: 286]
            [cite_start]return url, 0 # å†™å…¥å¤±è´¥ä¹Ÿè¿”å› 0 ä¸ªèŠ‚ç‚¹ [cite: 286]

        # å°†æå–åˆ°çš„èŠ‚ç‚¹ä¹Ÿå†™å…¥æ€»èŠ‚ç‚¹æ–‡ä»¶
        try:
            for node in unique_nodes:
                [cite_start]await all_nodes_writer.write(f"{node}\n") [cite: 287]
        except IOError as e:
            [cite_start]logging.error(f"å†™å…¥æ€»èŠ‚ç‚¹æ–‡ä»¶ {ALL_NODES_FILE} å¤±è´¥: {e}") [cite: 287]
            # è¿™é‡Œä¸è¿”å› 0ï¼Œå› ä¸ºèŠ‚ç‚¹å·²ç»æå–æˆåŠŸï¼Œåªæ˜¯å†™å…¥all.txtå¤±è´¥

        [cite_start]return url, len(unique_nodes) [cite: 287]

async def main():
    """
    ä¸»å‡½æ•°ï¼Œè¯»å– sources.list å¹¶å¹¶è¡Œå¤„ç† URLã€‚
    """
    [cite_start]await clean_old_cache_files(CLEANUP_THRESHOLD_HOURS) [cite: 287]

    if not os.path.exists('sources.list'):
        [cite_start]logging.error("sources.list æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·åˆ›å»ºå¹¶æ·»åŠ  URLã€‚") [cite: 287]
        return

    with open('sources.list', 'r', encoding='utf-8') as f:
        [cite_start]urls = [line.strip() for line in f if line.strip() and not line.startswith('#')] [cite: 288]

    # ä¸ºæ²¡æœ‰åè®®çš„ URL æ·»åŠ é»˜è®¤åè®®ï¼ˆhttps://ï¼‰
    [cite_start]processed_urls = [] [cite: 288]
    for url in urls:
        if not url.startswith(('http://', 'https://')):
            [cite_start]fixed_url = f"https://{url}" [cite: 288]
            [cite_start]logging.info(f"URL {url} ç¼ºå°‘åè®®ï¼Œå·²è‡ªåŠ¨æ·»åŠ ä¸º {fixed_url}") [cite: 288]
            [cite_start]processed_urls.append(fixed_url) [cite: 288]
        else:
            [cite_start]processed_urls.append(url) [cite: 289]

    if not processed_urls:
        [cite_start]logging.warning("sources.list ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ URLã€‚") [cite: 289]
        return

    [cite_start]node_counts = defaultdict(int) [cite: 289]
    [cite_start]semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT) [cite: 289]

    # ç¡®ä¿ all.txt åœ¨å¼€å§‹å¤„ç†å‰æ˜¯ç©ºçš„
    async with aiofiles.open(ALL_NODES_FILE, 'w', encoding='utf-8') as f:
        [cite_start]await f.truncate(0) # æ¸…ç©ºæ–‡ä»¶ [cite: 289]

    # åœ¨è¿™é‡Œæ‰“å¼€ä¸€æ¬¡ all_nodes_writerï¼Œå¹¶åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å…±äº«
    async with aiofiles.open(ALL_NODES_FILE, 'a', encoding='utf-8') as all_nodes_writer:
        [cite_start]tasks = [process_url(url, all_nodes_writer, semaphore) for url in processed_urls] [cite: 290]
        [cite_start]results = await asyncio.gather(*tasks, return_exceptions=True) [cite: 290]

        for result in results:
            if isinstance(result, tuple):
                url, count = result
                node_counts[url] = count
            else:
                [cite_start]logging.error(f"å¤„ç† URL æ—¶å‘ç”Ÿå¼‚å¸¸: {result}") [cite: 291]

    try:
        async with aiofiles.open(NODE_COUNT_CSV, 'w', encoding='utf-8', newline='') as f:
            [cite_start]await f.write("URL,NodeCount\n") [cite: 291]
            for url, count in node_counts.items():
                escaped_url = '"{}"'.format(url.replace('"', '""'))
                [cite_start]await f.write(f"{escaped_url},{count}\n") [cite: 292]
    except IOError as e:
        [cite_start]logging.error(f"å†™å…¥èŠ‚ç‚¹è®¡æ•° CSV æ–‡ä»¶ {NODE_COUNT_CSV} å¤±è´¥: {e}") [cite: 292]

    [cite_start]logging.info("æ‰€æœ‰ URL å¤„ç†å®Œæˆã€‚") [cite: 292]

if __name__ == "__main__":
    [cite_start]asyncio.run(main()) [cite: 292]
