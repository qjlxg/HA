name: Proxy Scraper

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-proxies:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        path: .

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install httpx[http2] aiofiles beautifulsoup4 pyyaml aiodns tenacity geoip2 maxminddb

    - name: Create data directory
      run: |
        mkdir -p ./data
        chmod -R 755 ./data

    - name: Run proxy scraper
      env:
        DATA_DIR: ./data
        CONCURRENCY_LIMIT: 20
      run: |
        pwd
        python proxy_scraper.py | tee scraper_output.log
        if [ $? -ne 0 ]; then
          echo "Proxy scraper failed, check scraper_output.log"
          cat scraper_output.log
          exit 1
        fi

    - name: Check generated files
      run: |
        ls -la ./data || echo "Data directory is empty or does not exist"

    - name: Commit and push results
      run: |
        git config user.name "GitHub Actions"
        git config user.email "github-actions@github.com"
        git add data/all.txt data/node_counts.csv data/protocol_stats.csv data/*.txt
        git status
        git commit -m "Update collected proxy nodes and stats" || echo "No changes to commit"
        git push || echo "No changes to push or push failed"
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      continue-on-error: true
