name: Proxy Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'

jobs:
  scrape-proxies:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        echo "--- 开始安装 pip ---"
        python -m pip install --upgrade pip
        echo "--- pip 安装完成 ---"
        echo "--- 开始安装其他依赖 ---"
        pip install beautifulsoup4 PyYAML aiofiles aiodns tenacity geoip2 maxminddb
        echo "--- 其他依赖安装完成 ---"
        echo "--- 开始安装/升级 httpx[http2] ---"
        pip install --upgrade "httpx[http2]"
        echo "--- httpx[http2] 安装/升级完成 ---"
        
    - name: Verify httpx version # 再次确认 httpx 版本
      run: |
        echo "--- 验证 httpx 版本 ---"
        pip show httpx
        python -c "import httpx; print(f'Loaded httpx version: {httpx.__version__}')"
        echo "--- httpx 版本验证完成 ---"

    - name: Verify Python script existence and readability # 检查脚本文件
      run: |
        echo "--- 检查 proxy_scraper.py 文件 ---"
        ls -l proxy_scraper.py
        cat proxy_scraper.py | head -n 10 # 打印脚本前10行，确认内容

    - name: Verify sources.list existence and content # 检查 sources.list 文件
      run: |
        echo "--- 检查 sources.list 文件 ---"
        ls -l sources.list
        cat sources.list # 打印 sources.list 内容

    - name: Ensure data and cache directories exist
      run: |
        mkdir -p data
        mkdir -p cache

    - name: Run Proxy Scraper
      run: |
        echo "--- 准备运行 proxy_scraper.py ---"
        python proxy_scraper.py
        echo "--- proxy_scraper.py 运行结束 ---"

    - name: Commit and push changes
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config user.name "GitHub Actions"
        git config user.email "actions@github.com"
        git add data/
        git commit -m "Update proxy nodes [skip ci]" || true
        git push
