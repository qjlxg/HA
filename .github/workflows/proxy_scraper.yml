name: proxy_scraper

on:
  workflow_dispatch: # 支持手动触发
  schedule:
    - cron: '0 0 * * *' # 每天 UTC 00:00 自动运行（北京时间 08:00）

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
      continue-on-error: false

    - name: Run Proxy Scraper Script
      run: |
        python proxy_scraper.py  # 直接运行脚本
      continue-on-error: false
      env:
        PYTHONPATH: ${{ github.workspace }}  # 确保项目根目录在 PYTHONPATH 中

    - name: Commit and Push changes
      run: |
        git config --global user.name 'GitHub Actions'
        git config --global user.email 'actions@github.com'
        git pull origin main --rebase || echo "无更改需要拉取或变基"
        git add data/
        git commit -m "自动更新代理节点和日志 $(date -u +'%Y-%m-%d %H:%M:%S UTC')" || echo "无更改需要提交"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Notify on failure
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          console.log(`工作流失败: ${process.env.GITHUB_JOB}。请检查日志: ${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`);
