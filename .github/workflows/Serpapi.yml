name: Clash Proxy Crawler

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests pyyaml beautifulsoup4 selenium

    - name: Install Chromium and ChromeDriver
      run: |
        sudo apt-get update
        sudo snap install chromium
        # 检查 ChromeDriver 是否已存在，若存在则删除
        if [ -f /usr/bin/chromedriver ]; then
          sudo rm /usr/bin/chromedriver
        fi
        # 创建符号链接
        sudo ln -s /snap/chromium/current/chromedriver /usr/bin/chromedriver
        # 验证 ChromeDriver
        chromedriver --version

    - name: Run crawler
      run: python clash_proxy_crawler.py

    - name: Commit and push results
      run: |
        git config --global user.name 'github-actions'
        git config --global user.email 'github-actions@github.com'
        git add sc/
        git commit -m "Update proxy data and stats" || echo "No changes to commit"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
