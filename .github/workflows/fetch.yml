name: Fetch and Parse Nodes

on:
  schedule:
    - cron: '0 0 * * *' # Run daily at 00:00 UTC
  workflow_dispatch: # Allows manual triggering

jobs:
  fetch_and_parse:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x' # Use the latest Python 3.x

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install aiohttp pyyaml loguru

    - name: Create sources.list (if not exists)
      # This step ensures that sources.list exists for the script to run.
      # In a real scenario, you would commit your actual sources.list file.
      run: |
        if [ ! -f sources.list ]; then
          echo "https://example.com/your-first-sub.txt" > sources.list
          echo "+date https://example.com/daily-sub-%Y%m%d.yml" >> sources.list
          echo "# Add your subscription links here, one per line." >> sources.list
          echo "# Use '+date ' prefix for date-formatted URLs (e.g., +date https://example.com/sub_%Y%m%d.txt)" >> sources.list
          echo "Please commit your actual sources.list file to the repository."
        fi
      shell: bash

    - name: Run fetch.py script
      run: python fetch.py

    - name: Upload output files
      uses: actions/upload-artifact@v4
      with:
        name: parsed-nodes-output
        path: |
          output/
          node_counts.csv
          errors.log
